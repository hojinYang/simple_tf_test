{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 128)\n",
      "(?, 32, 32, 128)\n",
      "(?, 16, 16, 128)\n",
      "(?, 10)\n",
      "step 0, accuracy 0.08\n",
      "step 0, test_accuracy 0.096\n",
      "training time 1.487 sec\n",
      "step 50, accuracy 0.14\n",
      "step 50, test_accuracy 0.192\n",
      "training time 1.460 sec\n",
      "step 100, accuracy 0.37\n",
      "step 100, test_accuracy 0.262\n",
      "training time 1.596 sec\n",
      "step 150, accuracy 0.28\n",
      "step 150, test_accuracy 0.306\n",
      "training time 1.444 sec\n",
      "step 200, accuracy 0.24\n",
      "step 200, test_accuracy 0.356\n",
      "training time 1.516 sec\n",
      "step 250, accuracy 0.39\n",
      "step 250, test_accuracy 0.342\n",
      "training time 1.479 sec\n",
      "step 300, accuracy 0.31\n",
      "step 300, test_accuracy 0.372\n",
      "training time 1.505 sec\n",
      "step 350, accuracy 0.37\n",
      "step 350, test_accuracy 0.402\n",
      "training time 1.476 sec\n",
      "step 400, accuracy 0.42\n",
      "step 400, test_accuracy 0.4\n",
      "training time 1.487 sec\n",
      "step 450, accuracy 0.46\n",
      "step 450, test_accuracy 0.416\n",
      "training time 1.478 sec\n",
      "step 499, accuracy 0.51\n",
      "step 499, test_accuracy 0.448\n",
      "training time 1.690 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras._impl.keras.datasets.cifar10 import load_data\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "(x_train, y_train), (x_test,y_test) = load_data()\n",
    "\n",
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def next_batch(num,data,labels):\n",
    "    idx = np.arange(0,len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10),axis=1)\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "labels = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "x_image = x\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "with tf.name_scope('conv1'):\n",
    "    w_conv1 = tf.Variable(tf.truncated_normal([7,7,3,128],stddev=0.01),name='weight')\n",
    "    b_conv1 = tf.Variable(tf.zeros([128]),name='biases')\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)\n",
    "    print(h_conv1.shape)\n",
    "\n",
    "with tf.name_scope('conv2_three_3by3_b/n'):\n",
    "    with tf.name_scope('bottleneck'):\n",
    "        w_conv2_b = tf.Variable(tf.truncated_normal([1,1,128,64],stddev=0.01),name='weight')\n",
    "        b_conv2_b = tf.Variable(tf.zeros([64]),name='biases')\n",
    "        h_conv2_b = tf.nn.relu(conv2d(h_conv1,w_conv2_b)+b_conv2_b)\n",
    "    with tf.name_scope('conv2_1'):\n",
    "        w_conv2_1 = tf.Variable(tf.truncated_normal([3,3,64,64],stddev=0.01),name='weight')\n",
    "        b_conv2_1 = tf.Variable(tf.zeros([64]),name='biases')\n",
    "        h_conv2_1 = tf.nn.relu(conv2d(h_conv2_b,w_conv2_1)+b_conv2_1)\n",
    "    with tf.name_scope('conv2_2'):\n",
    "        w_conv2_2 = tf.Variable(tf.truncated_normal([3,3,64,64],stddev=0.01),name='weight')\n",
    "        b_conv2_2 = tf.Variable(tf.zeros([64]),name='biases')\n",
    "        h_conv2_2 = tf.nn.relu(conv2d(h_conv2_1,w_conv2_2)+b_conv2_2)\n",
    "    with tf.name_scope('conv2_3'):\n",
    "        w_conv2_3 = tf.Variable(tf.truncated_normal([3,3,64,64],stddev=0.01),name='weight')\n",
    "        b_conv2_3 = tf.Variable(tf.zeros([64]),name='biases')\n",
    "        h_conv2_3 = tf.nn.relu(conv2d(h_conv2_2,w_conv2_3)+b_conv2_3)\n",
    "    with tf.name_scope('restore'):\n",
    "        w_conv2_r = tf.Variable(tf.truncated_normal([1,1,64,128],stddev=0.01),name='weight')\n",
    "        b_conv2_r = tf.Variable(tf.zeros([128]),name='biases')\n",
    "        h_conv2_r = tf.nn.relu(conv2d(h_conv2_3,w_conv2_r)+b_conv2_r)\n",
    "        print(h_conv2_r.shape)\n",
    "        p_conv = max_pool_2x2(h_conv2_r)\n",
    "        print(p_conv.shape)\n",
    "\n",
    "with tf.name_scope('fc'):\n",
    "    p_conv_flat = tf.reshape(p_conv, [-1,16*16*128])\n",
    "    w_fc = tf.Variable(tf.truncated_normal([16*16*128,10],stddev=0.01),name='weight')\n",
    "    b_fc = tf.Variable(tf.zeros([10]),name='biases')\n",
    "    logits = tf.matmul(p_conv_flat,w_fc)+ b_fc\n",
    "    print(logits.shape)\n",
    "\n",
    "with tf.name_scope('softmax'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "    train_op = tf.train.AdamOptimizer(1e-4).minimize(loss,global_step=global_step)\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./logs/1by1',sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(500):\n",
    "    batch = next_batch(100,x_train,y_train_one_hot.eval())\n",
    "    if(i%50 == 0 or i==499):\n",
    "        test_batch = next_batch(500,x_test,y_test_one_hot.eval())\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0],labels:batch[1]})\n",
    "        print(\"step %d, accuracy %g\"%(i,train_accuracy))\n",
    "        summary, test_accuracy = sess.run([merged, accuracy],feed_dict={x:test_batch[0],labels:test_batch[1]})\n",
    "        print(\"step %d, test_accuracy %g\"%(i,test_accuracy))\n",
    "        writer.add_summary(summary,global_step=sess.run(global_step))\n",
    "    start = time.time()\n",
    "    sess.run(train_op,feed_dict={x:batch[0],labels:batch[1]})\n",
    "    duration =time.time() - start\n",
    "    if(i%50 == 0 or i==499):\n",
    "        print(\"training time %.3f sec\"%(duration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
