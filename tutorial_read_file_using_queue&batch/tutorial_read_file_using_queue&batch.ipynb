{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "'''\n",
    "기본 원칙!\n",
    "1. 큐가 있고\n",
    "2. 큐에 값을 채워넣을 operation이 있고\n",
    "3. 큐가 빌 때 operation을 반복 실행시켜줄 queue runner가 있어야 한다.\n",
    "5. queue runner는 쓰레드를 사용하는데\n",
    "4. 그 쓰레드는 coordinator에 의해 관리된다. \n",
    "'''\n",
    "QUEUE_LEN = 20\n",
    "#1. 큐가 있고\n",
    "q = tf.FIFOQueue(QUEUE_LEN,\"float\")\n",
    "#2. 큐에 값을 채워넣을 operation이 있고\n",
    "enq_ops1 = q.enqueue_many(([1.,1.],))\n",
    "enq_ops2 = q.enqueue_many(([2.,2.],))\n",
    "enq_ops3 = q.enqueue_many(([3.,3.],))\n",
    "#3. 큐가 빌 때 operation을 반복 실행시켜줄 queue runner가 있어야 한다.\n",
    "qr = tf.train.QueueRunner(q,[enq_ops1,enq_ops2,enq_ops3])\n",
    "\n",
    "sess = tf.Session()\n",
    "#4. 쓰레드는 coordinator에 의해 관리된다.\n",
    "coord = tf.train.Coordinator()\n",
    "#5. queue runner는 쓰레드를 사용한다\n",
    "threads = qr.create_threads(sess,coord=coord,start=True)\n",
    "\n",
    "for step in range(20):\n",
    "    print(sess.run(q.dequeue()))\n",
    "#모든 쓰레드들을 정지 시킨다.\n",
    "coord.request.stop()\n",
    "#다음 코드를 진행하기전에, Queue Runner의 모든 쓰레드들이 정지될때 까지 기다린다.\n",
    "coord.join(threads)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#실용적인 코드\n",
    "\n",
    "#1. 큐 생성(#2 operation이 내포된)\n",
    "filename_queue = tf.train.string_input_producer([\"1\",\"2\",\"3\"],shuffle=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #4. 쓰레드는 coordinator에 의해 관리된다.\n",
    "    coord = tf.train.Coordinator()\n",
    "    #5. queue runner는 쓰레드를 사용한다. #3 qr과 쓰레드 동시 생성\n",
    "    threads = tf.train.start_queue_runners(coord=coord,sess=esss)\n",
    "    \n",
    "    for step in range(20):\n",
    "        print(sess.run(filename_queue.dequeue()))\n",
    "    \n",
    "    #모든 쓰레드들을 정지 시킨다.\n",
    "    coord.request.stop()\n",
    "    #다음 코드를 진행하기전에, Queue Runner의 모든 쓰레드들이 정지될때 까지 기다린다.\n",
    "    coord.join(threads)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reader와 decoder 도입한 코드\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"1\"],[\"2\"],[\"3\"], shuffle=False,\n",
    "                                               name='filename_queue')\n",
    "#dequeue 대신 파일에서 데이터를 읽어오는 Reader\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "#value를 parsing하는 decoder\n",
    "record_defaults = [ [\"null\"],[1],[1900],[\"null\"],[\"null\"]]\n",
    "\n",
    "ID, num, year, rtype , rtime = tf.decode_csv(value, record_defaults=record_defaults,\n",
    "                                             field_delim=',')\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    for i in range(100):\n",
    "        print(sess.run([ID, num, year, rtype , rtime]))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#image주소,label 꼴로 저장된 csv 파일 읽고 파싱하기\n",
    "\n",
    "csv_file = tf.train.string_input_producer([\"1\"],[\"2\"],[\"3\"], shuffle=False,\n",
    "                                               name='filename_queue')\n",
    "textReader = tf.TextLineReader()\n",
    "_,line = textReader.read(csv_file)\n",
    "imagefile,label = tf.decode_csv(line,record_default=['',''])\n",
    "image = tf.image.decode_jpeg(tf.read_file(imagefile),channels=3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for i in range(100):\n",
    "        image_value, label_value, imagefile_value = sess.run([image,label,imagefile])\n",
    "        plt.imshow(image_value)\n",
    "        plt.show()\n",
    "        print(label_value,imagefile_value)\n",
    "    coord.request_stop()\n",
    "    coord,join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#배치 처리를 도입한 코드\n",
    "#데이타 포맷: 2014,xv,121\n",
    "#결론은 데이터 하나를 읽는 법을 먼저 정의한 다음, batch를 통해 여러 개를 읽는다는 것!\n",
    "\n",
    "def read_data(file_name):\n",
    "    try:\n",
    "        csv_file = tf.train.string_input_producer([file_name],name='filename_queue')\n",
    "        textReader = tf.TextLineReader()\n",
    "        _,line = textReader.read(csv_file)\n",
    "        year,flight,time = tf.decode_csv(line,record_default=[[1900],[''],[0]])\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        exit()\n",
    "    return year,flight,time\n",
    "\n",
    "#입력 텐서의 shape이  [x,y,z] 일 경우 \n",
    "#tf.train.batch를 통한 출력은 [batch_size,x,y,z] 가 된다\n",
    "def read_data_batch(file_name,batch_size=10):\n",
    "    year, flight, time = read_data(file_name)\n",
    "    batch_year,batch_flight,batch_time = tf.train.batch([year,flight,time],\n",
    "                                                       batch_size=batch_size)\n",
    "    return batch_year,batch_flight,batch_time \n",
    "\n",
    "def main():\n",
    "    #coordinate 위에 코드가 있어햐 한다\n",
    "    #데이타를 집어넣기 전에 미리 그래프가 만들어져 있어야 함!\n",
    "    batch_year, batch_flight,batch_time = read_data_batch(TRAINING_FILE)\n",
    "    year = tf.placeholder(tf.int32,[None,])\n",
    "    flight = tf.placeholder(tf.string,[None,])\n",
    "    time = tf.placeholder(tf.int32,[None,])\n",
    "    \n",
    "    tt = time*10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        \n",
    "        #run을 돌려서 데이터를 받음\n",
    "        y_,f_,t_ = sess.run([batch_year, batch_flight,batch_time])\n",
    "        #실행 run\n",
    "        print(sess.run(tt,feed_dict={time:t_}))\n",
    "    coord.request_stop()\n",
    "    coord,join(threads)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#요렇게도 할 수 있다.\n",
    "\n",
    "def get_input_queue(csv_file_name,num_epochs = None):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for line in open(csv_file_name,'r'):\n",
    "        cols = re.split(',|\\n',line)\n",
    "        train_images.append(cols[0])\n",
    "        # 3rd column is label and needs to be converted to int type\n",
    "        train_labels.append(int(cols[2]) )\n",
    "    input_queue = tf.train.slice_input_producer([train_images,train_labels],\n",
    "                                               num_epochs = num_epochs,shuffle = True)\n",
    "\n",
    "    return input_queue\n",
    "'''\n",
    "get_input_queue 함수에, csv_file_name을 인자로 주면, \n",
    "이 파일을 한줄 단위로 읽어서, 첫번째는 파일명, 세번째는 라벨로 읽은 후에, \n",
    "각각 train_images와  train_lables에 각각 string과 int 형으로 저장한다\n",
    "그 다음이 배열을 가지고 tf.train.slice_input_producer를 사용하면 \n",
    "배열에서 데이타를 읽어 드리는 input queue 를 생성하는데, \n",
    "이때 인자로 shuffle = True로 주면 데이타를 리턴 할때 순차적으로 \n",
    "리턴하지 않고 셔플된 형태로 랜덤하게 리턴한다. \n",
    "'''\n",
    "def read_data(input_queue):\n",
    "    image_file = input_queue[0]\n",
    "    label = input_queue[1]\n",
    "    image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=FLAGS.image_color)\n",
    "    return image,label,image_file\n",
    "\n",
    "'''\n",
    "다음으로, 이 큐를 이용하여 이미지 파일명과, 라벨을 읽어서 \n",
    "이미지 파일 데이타(텐서)와 라벨로 읽는 코드를 read_data라는 함수로 구현하였다. \n",
    "입력값은 input_queue인데, input queue에서 데이타를 읽으면 첫번째는 이미지 파일명, \n",
    "두번째는 라벨이 되는데, 첫번째 파일명을 tf.image.decode_jpeg함수를 이용하여 \n",
    "텐서로 읽은후, 읽은 이미지 데이타와 라벨을 리턴하였다.\n",
    "'''\n",
    "\n",
    "def read_data_batch(csv_file_name,batch_size=FLAGS.batch_size):\n",
    "    input_queue = get_input_queue(csv_file_name)\n",
    "    image,label,file_name= read_data(input_queue)\n",
    "    image = tf.reshape(image,[FLAGS.image_size,FLAGS.image_size,FLAGS.image_color])\n",
    "    batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)\n",
    "\n",
    "                                                       #,enqueue_many=True)\n",
    "    batch_file = tf.reshape(batch_file,[batch_size,1])\n",
    "    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),\n",
    "        FLAGS.num_classes, on_value=1.0, off_value=0.0)\n",
    "    return batch_image,batch_label_on_hot,batch_file\n",
    "\n",
    "'''\n",
    "마지막으로, 배치로 데이타를 읽는 함수 부분에서 앞에 정의한 get_input_queue와 \n",
    "read_data 함수를 이용하여 데이타를 shuffle 된 상태로 읽은 후에, \n",
    "tf.train.batch를 이용하여 일정한 개수 (배치) 형태로 리턴하도록 하였다.\n",
    "'''\n",
    "\n",
    "\n",
    "#출처: http://bcho.tistory.com/1174?category=555440 [조대협의 블로그]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
